{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c142d3",
   "metadata": {},
   "source": [
    "### types of activation function\n",
    "Sigmoid Function.\n",
    "\n",
    "Hyperbolic Tangent Function (Tanh)\n",
    "\n",
    "Softmax Function.\n",
    "\n",
    "Softsign Function.\n",
    "\n",
    "Rectified Linear Unit (ReLU) Function.\n",
    "\n",
    "Exponential Linear Units (ELUs) Function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47bf50",
   "metadata": {},
   "source": [
    "### TYPES OF OPTIMIZERS :\n",
    "\n",
    "Gradient Descent.\n",
    "\n",
    "Stochastic Gradient Descent.\n",
    "\n",
    "Adagrad.\n",
    "\n",
    "Adadelta.\n",
    "\n",
    "RMSprop.\n",
    "\n",
    "Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b1bb8",
   "metadata": {},
   "source": [
    "### Loss function in Deep Learning\n",
    "\n",
    "Regression. MSE(Mean Squared Error) MAE(Mean Absolute Error) Hubber loss.\n",
    "\n",
    "Classification. Binary cross-entropy. Categorical cross-entropy.\n",
    "\n",
    "AutoEncoder. KL Divergence.\n",
    "\n",
    "GAN. Discriminator loss. Minmax GAN loss.\n",
    "\n",
    "Object detection. Focal loss.\n",
    "\n",
    "Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1730f2c",
   "metadata": {},
   "source": [
    "# CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a5fcc",
   "metadata": {},
   "source": [
    "## import the libraries`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e60d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40253038",
   "metadata": {},
   "source": [
    "pandas - used to perform data manipulation and analysis\n",
    "\n",
    "numpy - used to perform a wide variety of mathematical operations on arrays\n",
    "\n",
    "matplotlib - used for data visualization and graphical plotting\n",
    "\n",
    "seaborn # - built on top of matplotlib with similar functionalities\n",
    "\n",
    "os - used to handle files using system commands\n",
    "\n",
    "tqdm - progress bar decorator for iterators\n",
    "\n",
    "warnings - to manipulate warnings details, filterwarnings('ignore') is to ignore the warnings thrown by the modules (gives clean results)\n",
    "\n",
    "random - used for randomizing\n",
    "\n",
    "load_img - used for loading the image as numpy array\n",
    "\n",
    "tensorflow - backend module for the use of Keras\n",
    "\n",
    "Dense - single dimension linear layer\n",
    "\n",
    "Dropout - used to add regularization to the data, avoiding over fitting & dropping out a fraction of the data\n",
    "\n",
    "Activation - layer for the use of certain threshold\n",
    "\n",
    "Flatten - convert a 2D array into a 1D array\n",
    "\n",
    "Conv2D - convolutional layer in 2 dimension\n",
    "\n",
    "MaxPooling2D - function to get the maximum pixel value to the next layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88842e1f",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88406d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../input/utkface-new/UTKFace/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "age_labels = []\n",
    "gender_labels = []\n",
    "\n",
    "for filename in tqdm(os.listdir(BASE_DIR)):\n",
    "    image_path = os.path.join(BASE_DIR, filename)\n",
    "    temp = filename.split('_')\n",
    "    age = int(temp[0])\n",
    "    gender = int(temp[1])\n",
    "    image_paths.append(image_path)\n",
    "    age_labels.append(age)\n",
    "    gender_labels.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['image'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48402dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2 method to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcedecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zipa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Unzip the Dataset\n",
    "\n",
    "!unzip kagglecatsanddogs_3367a.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = []\n",
    "label = []\n",
    "\n",
    "for class_name in os.listdir(\"PetImages\"):\n",
    "    for path in os.listdir(\"PetImages/\"+class_name):\n",
    "        if class_name == 'Cat':\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(1)\n",
    "        input_path.append(os.path.join(\"PetImages\", class_name, path))\n",
    "print(input_path[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we create the dataframe for processing\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['images'] = input_path\n",
    "df['label'] = label\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdb103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "def load_dataset(directory):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(directory):\n",
    "        for filename in os.listdir(directory+label):\n",
    "            image_path = os.path.join(directory, label, filename)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(label)\n",
    "            \n",
    "        print(label, \"Completed\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "## convert into dataframe\n",
    "train = pd.DataFrame()\n",
    "train['image'], train['label'] = load_dataset(TRAIN_DIR)\n",
    "# shuffle the dataset\n",
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train.head()\n",
    "\n",
    "test = pd.DataFrame()\n",
    "test['image'], test['label'] = load_dataset(TEST_DIR)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09465ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing from keras datasets\n",
    "(X_train, y_train), (X_test,y_test) = tf.keras.datasets.cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16703b52",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to display grid of images\n",
    "plt.figure(figsize=(20, 20))\n",
    "files = df.iloc[0:25]\n",
    "\n",
    "for index, file, age, gender in files.itertuples():\n",
    "    plt.subplot(5, 5, index+1)\n",
    "    img = load_img(file)\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Age: {age} Gender: {gender_dict[gender]}\")\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f069dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or  to display grid of images\n",
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==1]['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "    plt.subplot(5,5, index+1)\n",
    "    img = load_img(file)\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Dogs')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f8f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to display image gray\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open(train['image'][0])\n",
    "plt.imshow(img, cmap='gray');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634af01b",
   "metadata": {},
   "source": [
    "## to avoid and find errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df['images']:\n",
    "    if '.jpg' not in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7358db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "l = []\n",
    "for image in df['images']:\n",
    "    try:\n",
    "        img = PIL.Image.open(image)\n",
    "    except:\n",
    "        l.append(image)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4233186",
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete them manually\n",
    "\n",
    "df = df[df['images']!='PetImages/Dog/Thumbs.db']\n",
    "df = df[df['images']!='PetImages/Cat/Thumbs.db']\n",
    "df = df[df['images']!='PetImages/Cat/666.jpg']\n",
    "df = df[df['images']!='PetImages/Dog/11702.jpg']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e01c2",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = img.resize((128, 128), Image.ANTIALIAS)\n",
    "        img = np.array(img)features.append(img)\n",
    "        \n",
    "    features = np.array(features)\n",
    "    # ignore this step if using RGB\n",
    "    features = features.reshape(len(features), 128, 128, 1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5706bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_features(df['image'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49519cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ad927",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gender = np.array(df['gender'])\n",
    "y_age = np.array(df['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##OR\n",
    "def extract_features(images):\n",
    "    features = []\n",
    "    for image in tqdm(images):\n",
    "        img = load_img(image, grayscale=True)\n",
    "        img = np.array(img)\n",
    "        features.append(img)\n",
    "    features = np.array(features)\n",
    "    features = features.reshape(len(features), 48, 48, 1)\n",
    "    return features\n",
    "\n",
    "train_features = extract_features(train['image'])\n",
    "test_features = extract_features(test['image'])\n",
    "\n",
    "## normalize the image\n",
    "x_train = train_features/255.0\n",
    "x_test = test_features/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ffd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert label to integer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(train['label'])\n",
    "y_train = le.transform(train['label'])\n",
    "y_test = le.transform(test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Or use this way to convert text to numbers \n",
    "y_train = to_categorical(y_train, num_classes=7)\n",
    "y_test = to_categorical(y_test, num_classes=7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140c177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.argmax(a, axis=None, out=None, *, keepdims=<no value>)[source]\n",
    "Returns the indices of the maximum values along an axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = keras.utils.to_categorical(\n",
    "    y_train, num_classes=10, dtype='float32'\n",
    ")\n",
    "y_test_categorical = keras.utils.to_categorical(\n",
    "    y_test, num_classes=10, dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b74af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a627a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0402541c",
   "metadata": {},
   "source": [
    "## `Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a331e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 1)\n",
    "inputs = Input((input_shape))\n",
    "# convolutional layers\n",
    "conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu') (inputs)\n",
    "maxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)\n",
    "conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu') (maxp_1)\n",
    "maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)\n",
    "conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu') (maxp_2)\n",
    "maxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)\n",
    "conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)\n",
    "maxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)\n",
    "\n",
    "flatten = Flatten() (maxp_4)\n",
    "\n",
    "# fully connected layers\n",
    "dense_1 = Dense(256, activation='relu') (flatten)\n",
    "dense_2 = Dense(256, activation='relu') (flatten)\n",
    "\n",
    "dropout_1 = Dropout(0.3) (dense_1)\n",
    "dropout_2 = Dropout(0.3) (dense_2)\n",
    "\n",
    "output_1 = Dense(1, activation='sigmoid', name='gender_out') (dropout_1)\n",
    "output_2 = Dense(1, activation='relu', name='age_out') (dropout_2)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[output_1, output_2])\n",
    "\n",
    "model.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b2f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR\n",
    "# input split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,  # normalization of images\n",
    "    rotation_range = 40, # augmention of images to avoid overfitting\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_iterator = train_generator.flow_from_dataframe(\n",
    "    train,x_col='images',\n",
    "    y_col='label',\n",
    "    target_size=(128,128),\n",
    "    batch_size=512,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_iterator = val_generator.flow_from_dataframe(\n",
    "    test,x_col='images',\n",
    "    y_col='label',\n",
    "    target_size=(128,128),\n",
    "    batch_size=512,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Image Generator rescale and normalizes the images by pixels between 0 and 1 for easier processing.\n",
    "\n",
    "## model creation\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "            Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
    "            MaxPool2D((2,2)),\n",
    "            Conv2D(32, (3,3), activation='relu'),\n",
    "            MaxPool2D((2,2)),\n",
    "            Conv2D(64, (3,3), activation='relu'),\n",
    "            MaxPool2D((2,2)),\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "    \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3rd way\n",
    "\n",
    "model = Sequential()\n",
    "# convolutional layers\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(output_class, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1eb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = model.fit(x=x_train, y=y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a99cd12",
   "metadata": {},
   "source": [
    "Dropout() - used to add regularization to the data, avoiding over fitting & dropping out a fraction of the data from the layers\n",
    "\n",
    "activation='sigmoid' - used for binary classification\n",
    "\n",
    "optimizer=’adam’ - automatically adjust the learning rate for the model over the no. of epochs\n",
    "\n",
    "loss='binary_crossentropy' - loss function for binary outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93635e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fac450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "history = model.fit(x=X, y=[y_gender, y_age], batch_size=32, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17874a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_flattened, y_test)\n",
    "\n",
    "y_predicted = model.predict(X_test_flattened)\n",
    "y_predicted[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938aa5d3",
   "metadata": {},
   "source": [
    "\n",
    "## Plot the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ec2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results for gender\n",
    "acc = history.history['gender_out_accuracy']\n",
    "val_acc = history.history['val_gender_out_accuracy']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "loss = history.history['gender_out_loss']\n",
    "val_loss = history.history['val_gender_out_loss']\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results for age\n",
    "loss = history.history['age_out_loss']\n",
    "val_loss = history.history['val_age_out_loss']\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ccfeb8",
   "metadata": {},
   "source": [
    "## to see the predection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 100\n",
    "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
    "# predict from model\n",
    "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
    "pred_gender = gender_dict[round(pred[0][0][0])]\n",
    "pred_age = round(pred[1][0][0])\n",
    "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
    "plt.axis('off')\n",
    "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b47c342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "388d316e",
   "metadata": {},
   "source": [
    "numpy.argmax(a, axis=None, out=None, *, keepdims=<no value>)[source]\n",
    "Returns the indices of the maximum values along an axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac50675",
   "metadata": {},
   "source": [
    "tf.keras.utils.to_categorical(y, num_classes=None, dtype=\"float32\")\n",
    "Arguments\n",
    "\n",
    "y: Array-like with class values to be converted into a matrix (integers from 0 to num_classes - 1).\n",
    "num_classes: Total number of classes. If None, this would be inferred as max(y) + 1.\n",
    "dtype: The data type expected by the input. Default: 'float32'.\n",
    "Returns\n",
    "\n",
    "A binary matrix representation of the input. The class axis is placed last."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46dbec4",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d628147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c23625",
   "metadata": {},
   "source": [
    "pandas - used to perform data manipulation and analysis\n",
    "\n",
    "numpy - used to perform a wide variety of mathematical operations on arrays\n",
    "\n",
    "nltk –  a natural language processing toolkit module associated in anaconda\n",
    "\n",
    "re – used as a regular expression to find particular patterns and process it\n",
    "\n",
    "stopwords - used to remove stop words from the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b82d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get necessary columns for processing\n",
    "df = df[['v2', 'v1']]\n",
    "# df.rename(columns={'v2': 'messages', 'v1': 'label'}, inplace=True)\n",
    "df = df.rename(columns={'v2': 'messages', 'v1': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed199c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279c3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove special characters\n",
    "    text = re.sub(r'[^0-9a-zA-Z]', ' ', text)\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # remove stopwords\n",
    "    text = \" \".join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afda996",
   "metadata": {},
   "source": [
    "Defined to call and clean the text to avoid repeating line by line if further cleaning is needed\n",
    "\n",
    "set(stopwords.words('...')) - used to load the unique list of common stop words from the specified language as tokens\n",
    "\n",
    "Stop words are not meaningful words, deleting those words will not affect the results\n",
    "\n",
    "Text are converted to lower case to avoid mismatching\n",
    "\n",
    "Special characters and extra spaces are removed\n",
    "\n",
    "Stop words removed from text by splitting the original text and comparing with the STOPWORDS list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487eb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the messages\n",
    "df['clean_text'] = df['messages'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a88778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8941f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "def classify(model, X, y):\n",
    "    # train test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, shuffle=True, stratify=y)\n",
    "    # model training\n",
    "    pipeline_model = Pipeline([('vect', CountVectorizer()),\n",
    "                               ('tfidf',TfidfTransformer()),\n",
    "                               ('clf', model)])\n",
    "    pipeline_model.fit(x_train, y_train)\n",
    "    \n",
    "    print('Accuracy:', pipeline_model.score(x_test, y_test)*100)\n",
    "    \n",
    "#     cv_score = cross_val_score(model, X, y, cv=5)\n",
    "#     print(\"CV Score:\", np.mean(cv_score)*100)\n",
    "    y_pred = pipeline_model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9aea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline - used for a linear sequence of data transforms to be chained together culminating in a modeling process that can be evaluated.\n",
    "\n",
    "train_test_split() - used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n",
    "\n",
    "cross_val_score() - used to split the data into (x) equal files, trains the data in (y) combinations and returns the (cv) calculated accuracy of the given model.\n",
    "\n",
    "CountVectorizer -  used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
    "\n",
    "TfidfVectorizer -  used to perform both word frequency and inverse document frequency of the text.\n",
    "\n",
    "TfidfTransformer - used to transform text into a meaningful representation of numbers which is used to fit machine algorithm for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "classify(model, X, y)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "classify(model, X, y)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(C=3)\n",
    "classify(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4a944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1040e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b196edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704468e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f4b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b04ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2676dc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757305fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
